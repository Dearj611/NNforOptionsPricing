\documentclass{report}
\usepackage{setspace}
\usepackage{subfigure}

\pagestyle{plain}
\usepackage{amssymb,graphicx,color}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{a4wide}
\usepackage{amsmath}

\newtheorem{theorem}{THEOREM}
\newtheorem{lemma}[theorem]{LEMMA}
\newtheorem{corollary}[theorem]{COROLLARY}
\newtheorem{proposition}[theorem]{PROPOSITION}
\newtheorem{remark}[theorem]{REMARK}
\newtheorem{definition}[theorem]{DEFINITION}
\newtheorem{fact}[theorem]{FACT}

\newtheorem{problem}[theorem]{PROBLEM}
\newtheorem{exercise}[theorem]{EXERCISE}
\def \set#1{\{#1\} }

\newenvironment{proof}{
PROOF:
\begin{quotation}}{
$\Box$ \end{quotation}}



\newcommand{\nats}{\mbox{\( \mathbb N \)}}
\newcommand{\rat}{\mbox{\(\mathbb Q\)}}
\newcommand{\rats}{\mbox{\(\mathbb Q\)}}
\newcommand{\reals}{\mbox{\(\mathbb R\)}}
\newcommand{\ints}{\mbox{\(\mathbb Z\)}}

%%%%%%%%%%%%%%%%%%%%%%%%%%


\title{{\vspace{-14em} \includegraphics[scale=0.4]{ucl_logo.png}}\\
{{\Huge Machine Learning on Options Pricing}}\\
{\large Optional Subtitle}\\
}
\date{Submission date: 1 April 2020}
\author{Wenwen Zheng\thanks{
{\bf Disclaimer:}
This report is submitted as part requirement for the BSc Computer Science at UCL. It is
substantially the result of my own work except where explicitly indicated in the text.
\emph{Either:} The report may be freely copied and distributed provided the source is explicitly acknowledged
\newline  
\emph{Or:}\newline
The report will be distributed to the internal and external examiners, but thereafter may not be copied or distributed except with permission from the author.}
\\ \\
BSc Computer Science\\ \\
Dr Dariush Hosseini }


\begin{document}
 
\onehalfspacing
\maketitle
\begin{abstract}
This report will provide an overview on fast substitutions to traditional option pricing techniques using DL. In particular, to examine current approaches. Starting with the ‘Deep Learning for Option Pricing’[Robert Culkin & Sanjiv R. Das] and ‘Supervised Deep Neural Networks’[Tugce Karatas, Amir Oskoui, Ali Hirsa], comparisons and assessments can be made in order to generate new ideas from their inspirations and verify my own findings. 

\end{abstract}
\tableofcontents
\setcounter{page}{1}


\chapter{Introduction}

\section{The problem}
Options, the derivatives based on the value of the underlying assets, are one important financial instruments in investments. The ability to predict the prices and the trends is essential for making trading decisions. The industry is still relying heavily on traditional analytic methods such as Monte-Carlo simulation, the Black-Scholes model to make estimations with assumptions that are known to be wrong in real-life scenarios. Noticing deep learning's impressing performances on predictions for regression problems, this project thus explores the possibilities of substituting the existing methods by trained neural networks, assesses and compares their performances under different situations, aiming for more stable and accurate outputs on particular financial products.

If machine learning methods are adapted well in this case, it is believed to provide strong support and reference for option pricing, enhancing the accuracy and speed of predictions.

Given the wide ranges of option products available in the market and the varieties of machine learning approaches, this project, narrows the scope by starting with the vanilla options and the classic deep learning model suggested by existing studies. Refinements and new inventions will be made along the experiments. The findings are then extended and applied to exotic options which represent more complicated scenarios in option pricing,  to examine if similar, better performances could be yield. 

\section{Aims and Deliverables}
This project aims to complete the following objectives:
\begin{itemize}
\item An examination of machine learning approaches to pricing a range of options products will be examined. There will be a particular focus on methods proposed by some recent papers. The focus will be the implementations for vanilla options, then for some exotic extensions.
\item A comparison of pricing speed on novel test points will be made between the ML approaches and traditional numerical approaches (particularly Monte-Carlo based mechanisms).
\item In addition, an examination of how the ML approaches can be used for hedging will be made, and a discussion of advantages and disadvantages vis a vis traditional methods will be considered.
\end{itemize}
After several rounds of experiments and analysis, the aim is to deliver following outputs:
\begin{itemize}
\item A review of literature pertaining to machine learning approaches to options pricing – in particular, NN/DL approaches
\item An implementation of a DL network to price vanilla Black Scholes options and an analysis of Greek stability and accuracy together with pricing speed vs traditional analytic and Monte-Carlo approaches will be made
\item The experiments will be repeated for a portfolio of exotic derivatives
\item Time-permitting, a consideration of implications, for example, for the findings for CVA (credit valuation adjustment) books within banks, will be made
\end{itemize}

\section{Annotated Contents}
This section gives a detailed summary of the project structure and the contents for each chapter.\\\\
\textbf{Chapter One: Introduction}\\
This chapter gives the basic information about the project and provides an overview of this report.\\
\textbf{Chapter Two: Literature Review}\\
This chapter details the related background knowledge prior to this project. It covers both financial and computer science related information. Explanations about options and deep learning in general and the works focusing on both aspects are provided. The scope is then limited to the types of options and specific models I would like to use. Some introductions about the traditional methods and existing neural networks for options pricing are mentioned as they will be used as references and comparisons in my assessment and evaluation.\\
\textbf{Chapter Three: Data and Pre-processing}\\
This chapter includes everything about the data we use throughout the project. The considerations about using solely synthetic data are elaborated. The chapter walks through the requirements for the datasets and the steps for generating the data. Both vanilla options and exotic options are generated in this project.\\
\textbf{Chapter Four: Experiments with Different Methods}\\
Several experiments based on existing papers are carried out in this chapter with new findings and refinements made accordingly. There are trained deep neural networks for both vanilla options and exotic options followed by comparisons to Monte-Carlo, one example of the traditional methods. Other than option pricing, we also look at the Greeks predictions and responding performances. Conclusions from the basic vanilla options are then extended to exotic options.\\
\textbf{Chapter Five: Evaluations and Conclusions}\\
Ending the report, the last chapter summaries the project, discusses the success and limitations of the findings， and explore possible future works.\\

\chapter{Literature Review}

\section{Options and Options Pricing}

Contents to be included:
\begin{itemize}
\item what's option (vanilla and exotic etc)
\item BS and the Greeks
\item Options price prediction, the Greeks, Monte-Carlo and its accuracy/stability because of unstable Greeks
\end{itemize}

\subsection{Options, the traditional financial instrument}
An option is a contract giving the buyer the right, but not the obligation, to buy (in the case of a call) or sell (in the case of a put) the underlying asset at a specific price on or before a certain date. A stock option contract typically represents 100 shares of the underlying stock, but options may be written on any sort of underlying asset from bonds to currencies to commodities.
In this project, we focus on two types of options, one is the classic vanilla call options, another is a Barrier Up-and-Out Put Options for our studies of exotic options. The vanilla option is set to be European options which could only be exercised only on the date of maturity. The Barrier option, on the other hand, depends on whether or not the underlying asset has reached or exceeded a predetermined price. In the case of a Barrier Up-and-Out Put Option, the option would expire worthless once the underlying exceeds the barrier price. Barrier options shares similar characteristics as the vanilla options but with added conditions to be considered. 

Option prices and the Greeks
\subsection{Pricing Methods and Performances}
Traditionally, several pricing methods are used to estimate theoretical option values.The simplest method to price the options is to use a binomial option pricing model. However,  the assumption of perfectly efficient markets over-simplifies the problem, making it not valuable for this project. The Black-Scholes model is another commonly used option pricing model. This project mainly builds upon this pricing theory as it was developed mainly for the pricing European options on stocks with a fair degree of assumptions made. Monte-Carlo methods are another focus in this project, mainly as a comparison to our models. They differentiate themselves from other option pricing techniques in the way that potential asset prices are generated in the process. Despite being relatively slow, Monte-Carlo methods are ideal for pricing options where the payoff is path dependent. To evaluate the performances of different methods under various circumstances, accuracy, speed and stability are highlighted. 

\section{Deep Learning}
Explain Deep Learning in a simple way\\
Types of Deep Learning (Methods to be used in this report)

\subsection{Deep Learning in Finance: Existing works}
Introduces the papers I've been studying and inspired. How they are approaching the problems

In this project ,we will use Python and Keras for building deep learning neural networks (explain the ml tools we gonna use in this project)

\chapter{Data and Pre-processing}
To price an option and other financial products, extensive amount of past data is essential. It's the same for Deep Learning if the aim is to generate accurate neural networks. Considering the focus of this project which is the examination of different methods' performances instead of real-life prediction for a particular option, using real market data introduces possibly more obstacles than benefits. The amount of valid data we have access is limited and careful cleansing must be carried out before applying to the project. Great amount of efforts would be spent on these steps which shouldn't be a focus in this project. Therefore, synthetic data is used throughout the project for both traditional methods and for trainings of new neural networks. This consistency and large quantity ensure that the comparisons and assessment made are valid and reasonable.

\section{Synthetic data}

\subsection{Vanilla Call Options}
We use Quantlib to simulate call options. Quantlib\footnote{https://www.quantlib.org/} is an open-source library widely used for quantitative finance with pricing engines available to use. To begin with, we look into and base our data on the classic Black-Scholes model. As a basic building block of derivative theories, Black-Schole model is able to set a theoretical value for a call or put option based on six variables: the type of the option, volatility, underlying stock price, time to maturity, strike price, and risk-free rate. The model yields the call price as below.\\

\begin{equation}
\mathrm C(\mathrm S,\mathrm t)= \mathrm N(\mathrm d_1)\mathrm S - \mathrm N(\mathrm d_2) \mathrm K \mathrm e^{-rt}
\label{eq:2}
\end{equation}

\begin{equation}
\mathrm d_1= \frac{1}{\sigma \sqrt{\mathrm t}} \left[\ln{\left(\frac{S}{K}\right)} + t\left(r + \frac{\sigma^2}{2} \right) \right]
\end{equation}

\begin{equation}
\mathrm d_2= \frac{1}{\sigma \sqrt{\mathrm t}} \left[\ln{\left(\frac{S}{K}\right)} + t\left(r - \frac{\sigma^2}{2} \right) \right]
\end{equation}

where 
\begin{itemize}
	\item[] C = Call option price 
	\item[] S = Current stock price
	\item[] K = Strike price of the option
	\item[] r = risk-free interest rate 
	\item[] $\sigma$ = volatility 
	\item[] t = time to maturity (in years)
	\item[] N = normal cumulative distribution function
\end{itemize}

The approach is to set a range of variables shown in Table \ref{tab:table1} and generate sets of data with a calculated call price. Note that this set of ranges and the initial way of normalising the training data which we will talk about later are both aligned with Robert Culkin & Sanjiv R. Das's \footnote{Do proper reference to the paper} paper as they are applicable to our project and allows easy comparisons between our results and the ones concluded by the paper.

\begin{table}[h!]
	\begin{center}
		\caption{Parameter ranges for vanilla call options}
		\label{tab:table1}
		\begin{tabular}{l|S|r} % <-- Changed to S here.
			\textbf{Variable}       & \textbf{Range}   \\
			Call option price       & $0 – $328        \\
			Current stock price     & $10 – $500       \\
			Strike price            & $7 – $650        \\
			Risk-free interest rate & 1\% – 3\%        \\
			Volatility              & 5\% – 90\%       \\
			Time to maturity        & 1 day to 3 years \\
			Dividend rate (q)       & 0\% – 3\%       
		\end{tabular}
	\end{center}
\end{table}


\subsection{Exotic options}

\subsection{Evaluation, Validation and Testing}
In this project, numerical values are returned and assessed mean square error (MSE) is used as the main measurement for accuracy. Time taken generating price outputs from different methods are also recorded to compare the speed.

Validation is needed because of the problem of peeking [\url{https://machinelearningmastery.com/difference-test-validation-datasets/}]. I realise that improvements could be made upon the suggested models in the first paper. 
A good definition of the three data sets was proposed in Ripley’s book “Pattern Recognition and Neural Networks” as follows:
– Training set: A set of examples used for learning, that is to fit the parameters of the classifier.\\
– Validation set: A set of examples used to tune the parameters of a classifier, for example to choose the number of hidden units in a neural network.\\
– Test set: A set of examples used only to assess the performance of a fully-specified classifier.\\
Despite having enough data for validation (as they could be generated endlessly), one seperate, independent validation set has limited ability to identify and assess the uncertainty of a model. [\url{Max Kuhn and Kjell Johnson, Page 78, Applied Predictive Modeling, 2013}]Therefore, cross-validation is preferred.

Evaluation and optimisation are two important steps to assess the performance of one model and to make refinements based on the feedback. Validation and testing data are needed. 
Despite cross-validation is the preferred and mainstream way to carry out the validation process in most machine learning cases, it is expensive in resources and chosen mainly because of the lack of data for other models. In this project, we will use one separate, independent validation data set directly as proper sample data can be generated endlessly. 


\chapter{Working on vanilla option pricing}

\section{A basic Deep Learning Model for Vanilla Option Pricing}
From the neural network structure and hyper-parameters suggested in the paper Deep Learning for Option Pricing’[Robert Culkin & Sanjiv R. Das], a basic deep learning model which have decent pricing ability on vanilla options is easily re-implemented. Normalisation of the initial input data and activation functions etc are all taken from the paper. 

(with comparison diagram? 

However, it doesn't return  performances on test data as accurate as suggested in the paper despite having the same training data and testing data. Validation is also missing in the original process. Therefore, manual tuning on the hyper-parameters and validation are added in with the aim to improve the performance.

Training data are directly set to be larger so that 20% of them are taken directly as the validation data in Keras model fit parameters. In additional to MSE, we then have the validation loss which gives a more objective assessment on the performance.

Manual tuning are done in a trial and error method. Dropout rate, activation functions etc parameters are modified to train a new neural network and evaluate separately. A early callback function is added in which basically stops the training when validation loss is no longer showing any improvements within three rounds. The tunings definitely improve the model to some extend, however, whether this is the best combination of the hyper-parameters in this case can not be told. (be more tech professional

\subsection{Hyper-parameter Optimisation}
Given the limitations in the manual tuning process, hyper-parameter optimisation is introduced in the process to finalise the set of hyper-parameters our model is going to use for all the later stages. GridSearch is firstly considered as suggested in the 'Hands on Machine learning with ... ''. However, after several trials, it is proven to be too expensive thus impractical in this project. 'https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf' Tree of Parzen Estimators (TPE) is preferred in this case as it helps to find optimal parameters with informed search and 'learns' from previous iretations to avoid unnecessary efforts on unpromising areas of the search space. Python library HyperOpt (https://github.com/hyperopt/hyperopt) is used in the implementation and the chosen hyper-parameters for the turning are ....... Weights from the best model are then saved and loaded directly as the final deep learning model.

Assessments on performances - speed (various data size), accuracy, Greek stability etc
Based on results, make improvements and suggest different user cases\\
Train the DL model and the traditional method for exotic options\\
Run tests and comparisons again for new conclusions

\subsection{Implementation of  traditional Monte-Carlo method}
Monte-Carlo simulation is also studied as a representative of traditional pricing methods. It is based on repeated computation and random sampling. Firstly, it will generate a large number of potential future prices of the underlying securities. Payoff for each prices will be calculated and discounted back to current value. The final prediction is given as the average of all the discounted payoffs. This method, despite introducing more noise and uncertainty,  is widely used in option pricing especially when the payoff is determined by different paths or a basket of assets. 

We use the Monte-Carlo pricing engine in Quantlib to generate the model and make predictions.  The same inputs and settings from the analytic Black-Scholes model we implemented in data processing are used. Only the pricing engine is switched in this case. The model gives decent performance on prediction accuracy, however, with a much slower speed.

\subsection{The Greeks}

Options traders often refer to the delta, gamma, vega, and theta of their option positions. Collectively, these terms are known as the Greeks, and they provide a way to measure the sensitivity of an option's price to quantifiable factors. (https://www.investopedia.com/trading/using-the-greeks-to-understand-options/) They reflect how the option prices will change responding to the changes in underlying assets' prices, the market volatility etc, thus a useful tool to better understand the risk and potential reward of an option position. 

The Greeks for all three methods are generated in different ways. For analytic BSM method, Quantlib pricing engine calculates the Greeks when generating the option price,  giving us the results straightforward. 
\subsection{Examination with Traditional Methods}
\subsection{Extension to Exotic Options Pricing}

\section{Supervised Deep Neural Network (DNN)}
Focus on ‘Supervised Deep Neural Networks’[Tugce Karatas, Amir Oskoui, Ali Hirsa]\\
Train the supervised DNN model suggested in the paper and make variations to work for both vanilla options and exotic options\\
Run assessments during several stages and draw conclusions along the process

\subsection{DNN Implementation on Vanilla options}
\subsection{Examination with Traditional Methods}
\subsection{Extension to Exotic Options Pricing}

\section{Possible extensions on CVA}
\subsection{Implementation Details}
\subsection{Result Analysis}


\chapter{Evaluations and Conclusions}
\section{Achievements and Deliverables}
Summarise the achievements to confirm the project goals have been met.
\section{Evaluation}
Evaluation of the work (this may be in a separate chapter if there is substantial evaluation).
\section{Future Work}
How the project might be continued, but don't give the impression you ran out of time!

\appendix


\begin{thebibliography}{HHM99}


\bibitem[Pri70]{PriorNOP70}  %only an example
A.~Prior.
\newblock The notion of the present.
\newblock {\em Studium Generale}, 23:  245--248, 1970.


\bibitem[Rey97]{Rey:D}
M.~Reynolds.
\newblock A decidable temporal logic of parallelism.
\newblock {\em Notre Dame Journal of Formal Logic}, 38(3):  419--436,
  1997.
\end{thebibliography}
\chapter{Other appendices, e.g., code listing}
Put your appendix sections here

\end{document}